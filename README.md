We are analyzing various graph distance metrics to assess their correlations with the accuracy degradation of Graph Neural Networks (GNNs) under white-box gradient-based adversarial attacks. By examining the structural perturbations induced by the attack, we aim to identify which distance metrics most effectively capture the vulnerability and resilience of the GNNs. This involves quantifying the degree of structural and topological deviation within the graph and correlating these metrics with the resultant accuracy shifts. Our goal is to provide a nuanced understanding of how specific distance metrics, such as Graph Edit Distance, Wasserstein Distance, or Laplacian Spectral Distance, predict the sensitivity of GNNs to adversarial manipulations. Through this sophisticated analysis, we hope to uncover insights into the interplay between graph topology and GNN robustness.
